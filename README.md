# NYC_Taxi_Trips_analysis

In this project, I worked on analyzing a large dataset of taxi trips in New York City using Apache Spark, a popular big data processing framework. The goal of the project was to gain insights into the dataset by summarizing interzonal travel, and ranking zones by traffic, passenger volume, and profitability. I also recorded the execution time of the pipeline under different conditions and analyze the effect of dataset size ('S', 'M', 'L', 'XL', 'XXL'), dataset format (parquet and delta), and task complexity on pipeline performance.
evaluated the resulting execution times to comment on the effect of dataset size, dataset format, and task complexity on analysis pipeline performance.

To start, I performed data preprocessing and cleaning to ensure the data was ready for analysis. Then, I computed new columns such as zone names and unit profitability for each trip. Next, I summarized interzonal travel by building a graph data structure of zone-to-zone traffic and obtained aggregate information about all trips between those zones. I used this graph to rank zones by traffic, passenger volume, and profitability. Finally, I recorded the execution time of the entire pipeline and the pipeline without task 'Removing outliers using the modified z-score' on the two tables, for all dataset sizes and formats. I analyzed the resulting execution times and commented on the effect of dataset size, dataset format, and task complexity on pipeline performance.

Overall, this project was a valuable learning experience that helped me develop my skills in big data analytics and data processing. This project help us understand how the pipeline performs under different conditions and how we can optimize the pipeline for better performance. The insights gained from this analysis could be used to inform policy decisions related to the taxi industry in New York City.
